# RPA-PORT-PLATFORM — Comprehensive System Audit
## 22/02/2026 14:57 Israel Time

**Audited by:** Claude Opus 4.6 (6 parallel audit agents)
**Scope:** Full codebase — Input, Processing, Output, API, Costs, Security, Tests
**Codebase:** 64,231 lines across lib/*.py, 33 active tools, ~83 Firestore collections
**Latest commit:** `84d9d12` — fix: Section 9 justification renders in Hebrew
**CI Status:** Deploy #249 GREEN (3m41s), Tests #259 GREEN (36s) — both on commit `84d9d12`
**Test Suite:** 1,178 passed, 5 failed (pre-existing BS4), 2 skipped

---

## EXECUTIVE SUMMARY

| Severity | Count | Key Theme |
|----------|-------|-----------|
| **CRITICAL** | 4 | Missing external email guard, Gemini quota flag sticks, full-collection Firestore streams, monitor agent creates re-processing storms |
| **HIGH** | 8 | send_authorized never promoted, classify+clarification double-fire, seller website SSRF, stale verification cache, bare excepts, unpinned deps |
| **MEDIUM** | 23 | Cost blind spots, prompt bloat, keyword overlaps, race conditions, fragile parsing, asymmetric confidence, documentation drift |
| **LOW** | 18 | Code hygiene, edge cases, hardcoded lists, redundant checks |
| **TOTAL** | **53** | |

**Estimated monthly cost at 100 classifications/day: $400–$666**

---

## SECTION 1: CRITICAL FINDINGS (Fix First)

### CRIT-1: External Recipient Blocking Was Lost
**Files:** `rcb_helpers.py:712-804`
**Evidence:** CLAUDE.md Session 52B documents `BLOCKED_EXTERNAL_SEND` and `BLOCKED_EXTERNAL_REPLY` security log events. Grep across entire codebase returns **zero matches**. Neither `helper_graph_send()` nor `helper_graph_reply()` check if `to_email` is `@rpa-port.co.il` before sending. The `to_email=None` guard on `helper_graph_reply` (documented Session 52) is also absent.
**Impact:** If any code path passes an external email address, the email goes out to the external party. The quality gate Rule 5 only blocks self-send (`rcb@`), not arbitrary external addresses.
**Risk:** Classification reports, tracker updates, or intent replies could leak to external parties if a bug in any upstream module passes the wrong email.

### CRIT-2: `_gemini_quota_exhausted` Persists Across Cloud Function Invocations
**File:** `classification_agents.py:163`
**Evidence:** Module-level `_gemini_quota_exhausted = False`. Cloud Functions reuse containers. After ONE Gemini 429, this flag stays `True` for ALL subsequent requests in that container — potentially hours — with no TTL or auto-reset.
**Impact:** After any single Gemini quota hit, every subsequent classification in that container falls back to Claude at 15x the cost ($0.001→$0.015 per tool-calling round). Daily cost can spike from $3 to $90 if this happens early in the day.

### CRIT-3: `query_tariff()` Streams Entire Tariff Collection (11,753 docs)
**File:** `classification_agents.py:647-661`
**Evidence:** `db.collection('tariff').stream()` reads ALL 11,753 tariff documents into memory, then does linear substring matching. This runs once per `run_full_classification()`.
**Impact:** ~11,753 Firestore reads per classification. At 100/day = 1.175M reads/day. Firestore charges $0.06/100K reads = ~$21/month from this single function. The tool engine's `search_tariff` (tool #2) already does indexed queries — this is a redundant legacy path.

### CRIT-4: Monitor Agent Deletes `rcb_processed` Docs, Causing Re-processing Storms
**File:** `main.py:1181-1228`
**Evidence:** `monitor_agent` (every 5 min) has two destructive behaviors:
1. If `rcb_processed` has >20 docs, deletes all older than 3 days — but email handler uses 2-day lookback. 1-day overlap window causes double-processing.
2. If >3 "failed" subjects found (processed without matching classification), deletes up to 5 `rcb_processed` docs to "retry". BUT: CC observations, brain commands, knowledge queries, tracker-only emails ALL write `rcb_processed` without producing `rcb_classifications`. Monitor misidentifies them as "failed" and re-processes every 5 minutes.
**Impact:** CC shipping emails get re-processed indefinitely. Duplicate deals, duplicate observations, wasted Firestore writes.

---

## SECTION 2: HIGH FINDINGS (Fix Soon)

### HIGH-1: `send_authorized` Never Promoted for CC-Originated Deals
**File:** `tracker.py:1248-1251` (creation) vs `1335-1498` (update)
`send_authorized` is only set at deal creation: `bool(_from.endswith('@rpa-port.co.il'))`. Deals created from CC emails (external senders like shipping lines) get `send_authorized=False`. When a team member later sends a direct email about the same deal, `_update_deal_from_observation()` never upgrades `send_authorized`. The deal stays forever unsendable.
**Impact:** Most CC-originated deals (the majority) never generate tracker status emails, even when team members interact with them.

### HIGH-2: INSTRUCTION Classify + Missing Attachment Double-Fires
**Files:** `main.py:993`, `email_intent.py:1162-1167`
When a team member writes "classify this" with no attachment, the intent handler sends a "missing attachment" clarification reply (status `"clarification_sent"`). Back in main.py, `"clarification_sent"` doesn't match `('replied', 'cache_hit')`, so code falls through to the classification pipeline — which then runs on empty data, producing items=0.
**Impact:** User gets BOTH a "please attach a document" reply AND an empty classification email.

### HIGH-3: `_fetch_seller_website()` Bypasses Domain Allowlist (SSRF Risk)
**File:** `tool_executors.py:2327-2397`
Tool #33 makes `requests.get(url)` to arbitrary seller domains, completely bypassing `_safe_get()` and the domain allowlist. `_infer_seller_domain()` constructs domains from invoice text — an attacker could craft a malicious invoice with a seller name that resolves to an internal IP.
**Impact:** Potential Server-Side Request Forgery. Limited by Cloud Functions network isolation but still a security concern.

### HIGH-4: Verification Engine Module-Level Cache Never Refreshes
**File:** `verification_engine.py:123-156`
`_cached_directives` and `_cached_framework_order` are module-level variables populated on first call and reused across ALL requests in the same container. Unlike `tool_executors.py` (per-request caching), updates to Firestore are invisible for the container's lifetime.
**Impact:** Updated classification directives or framework order documents ignored for hours.

### HIGH-5: Cross-Reference Confidence Adjustments May Not Apply
**File:** `tool_calling_engine.py:447-494`
Step 7d2 computes EU TARIC / US HTS confidence adjustments (+0.12 both agree, -0.05 neither), storing them in `cross_reference` output dict. But downstream code in `classification_agents.py` must read and apply these. If the wiring is incomplete, cross-reference validation has zero effect on final scores.
**Impact:** The entire cross-reference pipeline (tools #23+#24) produces data that may never influence the classification.

### HIGH-6: 7 Bare `except:` Clauses Remain
**Files:** `doc_reader.py:361`, `pc_agent.py:502`, `pdf_creator.py:76`, `rcb_email_processor.py:101,155,171,179`
These catch `SystemExit`/`KeyboardInterrupt` and silently swallow all errors. Session 38c fixed `rcb_helpers.py` and `main.py` but missed these 7.

### HIGH-7: No Pinned Upper-Bound Versions in requirements.txt
All 14 dependencies use `>=` minimum only. A future `pip install` could pull a breaking major version with no warning.

### HIGH-8: No Dependency Vulnerability Scanning in CI
No `pip audit`, `safety check`, or Dependabot. Known CVEs in dependencies would go undetected.

---

## SECTION 3: COST & EFFICIENCY ANALYSIS

### Monthly Cost Model (100 classifications/day = 3,000/month)

| Component | Gemini Working (80%) | Gemini Down (429) | Notes |
|-----------|---------------------|-------------------|-------|
| Tool-calling engine | $9-30 | $90-270 | 5-15 rounds × 3K classifications |
| Agent 2 (Claude Sonnet 4) | $90-240 | $90-240 | Always Claude, no fallback |
| Agents 1,3,4,5,6 | $15-30 | $45-90 | Gemini→Claude fallback |
| Cross-check (3 models) | $9 | $9 | Independent models |
| Elimination D6/D7 | $6-15 | $15-30 | AI only when >3 survivors |
| Verification engine | $3-9 | $3-9 | UK tariff + Gemini |
| Overnight brain (30 runs) | $105 | $105 | Budget-capped $3.50/run |
| Firestore reads | $10-30 | $10-30 | CRIT-3 dominates |
| Cloud Functions compute | Free tier | Free tier | 54% used by rcb_check_email |
| External APIs | $0 | $0 | All free tier |
| **TOTAL** | **$247-$468** | **$367-$783** | |

### Key Cost Drivers

1. **Agent 2 (Claude Sonnet 4):** $90-240/month — the single most expensive component. Consider Gemini Pro trial ($1.25/$10 vs $3/$15 = 60% cheaper).
2. **CRIT-3 full tariff stream:** ~$21/month in wasted Firestore reads. Trivially fixable.
3. **CRIT-2 Gemini sticking:** When triggered, costs can triple for the rest of the container's life.
4. **System prompt bloat:** 23.5K chars sent on every tool-calling round. At 15 rounds × $3/M tokens = $0.04/classification just for prompt repetition (Claude path).

### Firestore Read Budget

| Operation | Reads/Day | Reads/Month |
|-----------|-----------|-------------|
| `query_tariff()` full stream | 1,175,300 | 35,259,000 |
| Tool execution (tool loop) | 40,000-150,000 | 1.2M-4.5M |
| Memory/regulatory checks | 15,000-30,000 | 450K-900K |
| Tracker poll (48 cycles) | 5,280 | 158,400 |
| Monitor agent (288 cycles) | 2,000-5,000 | 60K-150K |
| Overnight brain | 25,000 | 750,000 |
| **TOTAL** | **~1.26M** | **~37.8M** |

Firestore free tier: 50K reads/day. **Current architecture exceeds free tier by 25x on classification days.** The $0.06/100K reads pricing means ~$22/month in Firestore reads.

### Cloud Function Compute Budget

`rcb_check_email` (every 2 min, 1GB, ~10s avg) = 216,000 GB-seconds/month = **54% of free tier** (400K GB-s/month). Adding other functions brings total to ~280,000 GB-s/month. Within free tier but tight.

### Gemini Free Tier Risk

| Model | Free Limit | Daily Usage (est.) | Days Until 429 |
|-------|-----------|-------------------|----------------|
| Gemini Flash | ~500 req/day | 500-1,500 | **Day 1** |
| Gemini Pro | ~50 req/day | 10-30 | Day 2-3 |

**The Gemini free tier is fundamentally inadequate for 100 classifications/day.** The system will hit 429 daily, forcing Claude fallback at 15x cost. Upgrading to Gemini paid tier ($0.075/M tokens Flash) would cost ~$3-10/month and eliminate all 429-related cost spikes.

---

## SECTION 4: INPUT PIPELINE

### Email Processing Flow (current state)

```
rcb_check_email (every 2 min, 1GB, 540s)
  ├─ Fetch last 2 days of emails from Graph API
  ├─ For each email:
  │   ├─ Skip if from rcb@rpa-port.co.il (self-loop)
  │   ├─ Skip if from cc@rpa-port.co.il (digest group)
  │   ├─ Skip if hash in rcb_processed (dedup)
  │   ├─ Determine: is_direct (TO) vs CC
  │   ├─ CC PATH:
  │   │   ├─ Pupil (silent learning)
  │   │   ├─ Tracker (process email, add observation)
  │   │   ├─ Schedule email detection
  │   │   └─ [Gap 2 auto-trigger is DEAD — code removed Session 52B]  ← MEDIUM
  │   └─ DIRECT PATH:
  │       ├─ Tracker
  │       ├─ Pupil
  │       ├─ Brain Commander
  │       ├─ Email Intent (questions, status, customs Q)
  │       ├─ Knowledge Query fallback
  │       ├─ External rate limit (5/hour)  ← case mismatch bug
  │       └─ Classification pipeline
  └─ mark_read (inconsistent — not called after classification)
```

### Medium Findings — Input Pipeline

| ID | Issue | File | Impact |
|----|-------|------|--------|
| M-P1 | `datetime.utcnow()` deprecated (Python 3.12+) | `main.py:785` | Deprecation warning |
| M-P2 | Rate limit case mismatch (`.lower()` query vs raw storage) | `main.py:1093 vs 1122` | External senders can bypass 5/hr limit with different capitalization |
| M-P3 | Gap 2 auto-trigger is dead (removed with CC intent handler) | `main.py:918-928` | Classification from accumulated CC docs never fires |
| M-P4 | `rcb_processed` + `rcb_classifications` full collection scans every 5 min | `main.py:1208-1215` | Grows unbounded, approaching timeout |
| M-P5 | Scanned PDF AI Vision only renders page 1 | `extraction_adapter.py:142` | Multi-page scanned invoices lose all data from page 2+ |
| M-P6 | CUSTOMS_QUESTION regex matches any `NNNN.NN` pattern | `email_intent.py:110` | Invoice amounts, IP addresses trigger false customs questions |
| M-P7 | TOCTOU race in classification readiness check | `tracker.py:1532-1544` | Two emails for same deal can both trigger classification |
| M-P8 | `follower_email` may be external with no fallback | `tracker.py:2372` | Tracker emails silently suppressed for externally-originated deals |
| M-P9 | Identity graph write-only integration — search not used for deal matching | `identity_graph.py` vs `tracker.py` | Invoice/PO/file-number matching capability unused |
| M-P10 | Identity graph does up to 144 Firestore reads per link attempt | `identity_graph.py:254-341` | Expensive search with no composite index |

---

## SECTION 5: PROCESSING PIPELINE

### Classification Flow (current state)

```
run_full_classification():
  ├─ Agent 1: Extract items from document (Gemini→Claude→ChatGPT triple fallback)
  ├─ If items=0: CLARIFICATION flow (GPT-4o — expensive!)
  ├─ query_tariff() — STREAMS 11,753 DOCS  ← CRIT-3
  ├─ Pre-classify bypass (memory confidence ≥90%)
  ├─ Elimination engine (D1-D8, 2,282 lines)
  ├─ Tool-calling engine (Gemini→Claude, max 15 rounds, 180s, 33 tools)
  │   ├─ Step 4b: Pre-enrichment (country, currency, food, medical, chemical, cosmetics)
  │   ├─ Steps 5-7: AI tool loop (search, verify, chapter notes, etc.)
  │   └─ Step 7d2: Cross-reference (EU TARIC + US HTS)
  ├─ Agent 2: Classification reasoning (Claude Sonnet 4 always)
  ├─ Agents 3-5: Regulatory, FTA, Risk (Gemini Flash)
  ├─ Agent 6: Synthesis (Gemini Pro)
  ├─ Verification engine (Phase 4+5, bilingual + knowledge)
  ├─ Cross-checker (3-way: Gemini Pro + Flash + GPT-4o-mini)
  ├─ audit_before_send() quality gate
  └─ Build email (14 section builders)
```

### Medium Findings — Processing

| ID | Issue | File | Impact |
|----|-------|------|--------|
| M-CL1 | Feature flags hardcoded `True` with no runtime toggle | `classification_agents.py:155-160` | Must deploy to disable a broken feature |
| M-CL2 | Agent 2-5 JSON parsing via string slicing (`find('{')`) is fragile | `classification_agents.py:685-702` | Occasional parsing failures on valid AI output |
| M-CL3 | Forced final answer on max rounds produces unverified HS codes | `tool_calling_engine.py:695-713` | 13+ item invoices may get partial results |
| M-CL4 | System prompt is 23.5K chars, sent on every tool round | `tool_definitions.py:796-886` | ~$0.04/classification just for prompt repetition |
| M-CL5 | GIR 3b essential character picks "first" material, not dominant | `elimination_engine.py:1478-1489` | Multi-material products may be misclassified |
| M-CL6 | Section scope elimination uses keyword overlap — fails on colloquial terms | `elimination_engine.py:515-598` | "Vape pen" may not match Section XVI (Machinery) |
| M-CL7 | Verification engine confidence asymmetric: +0.20 max / -0.30 min | `verification_engine.py:446` | Biased toward lowering confidence |
| M-CL8 | `format_legal_context_for_prompt()` always includes ALL 22 sections | `customs_law.py:759-773` | ~2.5K wasted tokens per round from irrelevant sections |
| M-CL9 | Pre-enrichment trigger keywords overlap (acid → both chemical + cosmetics) | `tool_calling_engine.py:77-110` | Unnecessary dual API calls adding 1-3s latency |
| M-CL10 | `search_open_beauty` has `"required": []` — AI can call with no args | `tool_definitions.py:651` | Wasted tool call returning error |
| M-CL11 | `audit_before_send()` retry sends same prompt on failure | `classification_agents.py:~1452` | Wasted tokens on identical failures |

---

## SECTION 6: OUTPUT PIPELINE

### Email Templates Status

| Template | Architecture | Quality | Issues |
|----------|-------------|---------|--------|
| Classification report | 14 section builders + orchestrator | Good | Cross-ref section exists but may not get data (HIGH-5) |
| Tracker status | 7 section builders + orchestrator | Good | send_authorized blocking most CC deals (HIGH-1) |
| Error templates | Branded RPA header/footer | Good | items=0 CLARIFICATION works correctly |
| Morning/afternoon digest | v4 template, 4 ports | Good | Port data limited (carrier APIs not configured) |
| Intent replies | Hebrew RTL | Adequate | Clarification for NONE intent can be annoying |
| Gate cutoff alerts | 3 severity levels | Good | Missing deal_id/alert_type for dedup (fixed in Session 52) |

### Output Findings

| ID | Issue | Severity | Impact |
|----|-------|----------|--------|
| M-O1 | `report_builder.py` correctly renders `decision_he`/`reasoning_he` | INFO | Working as designed after commit 84d9d12 |
| M-O2 | Quality gate Rule 7 HS regex fragile for Israeli format | MEDIUM | May miss XX.XX.XXXXXX/X format |
| M-O3 | CLAUDE.md claims security features that don't exist in code | MEDIUM | Documentation drift — leads to false confidence |
| L-O1 | Classification emails not marked read after processing | LOW | Re-scanned every poll but dedup prevents reprocessing |

---

## SECTION 7: SECURITY

### Authentication & Authorization

| Endpoint | Auth | CORS | Risk |
|----------|------|------|------|
| `api()` | Bearer token (RCB_API_SECRET) | `*` | Token-protected but CORS wide open |
| `rcb_api()` | Bearer token (health is public) | `*` | Same |
| All scheduler functions | Firebase internal | N/A | Secure |
| Email processing | Graph API token | N/A | Secure |

### Data Protection

| Data Type | External Exposure | Status |
|-----------|-------------------|--------|
| Deal IDs | Never sent to external APIs | GOOD |
| Customer names | Sent to OpenSanctions for screening | ACCEPTABLE (compliance) |
| Email addresses | Stored in Firestore, never sent externally | GOOD |
| Invoice content | Sent to Gemini/Claude for classification | ACCEPTABLE (necessary) |
| HS codes | Sent to EU TARIC / USITC for cross-ref | GOOD (public data) |

### Secrets Management

| Item | Status | Risk |
|------|--------|------|
| `sa-key.json` in .gitignore | YES | LOW |
| PAT token in git remote URL | VISIBLE in `git remote -v` | MEDIUM — anyone with repo access sees it |
| API keys `.strip()` on retrieval | YES | GOOD |
| 7 carrier API secrets | Defined in code, never configured | LOW (unused) |
| `AISSTREAM_API_KEY` | Not configured | LOW (port schedule degraded) |

### Security Summary

| Finding | Severity | Detail |
|---------|----------|--------|
| External recipient blocking lost (CRIT-1) | CRITICAL | Documented as fixed, not in code |
| Seller website SSRF (HIGH-3) | HIGH | Direct requests.get() to arbitrary domains |
| 7 bare except: clauses (HIGH-6) | HIGH | Swallow SystemExit |
| PAT token in git remote URL | MEDIUM | Visible to anyone with repo clone |
| No dependency vulnerability scanning (HIGH-8) | HIGH | Zero CVE detection |
| CORS `*` on authenticated endpoints | LOW | Token protects data but CORS allows any origin |

---

## SECTION 8: TESTS & CODE QUALITY

### Test Suite

```
Total: 1,178 passed, 5 failed (pre-existing BS4), 2 skipped
```

| Test File | Tests | Module Covered |
|-----------|-------|---------------|
| test_customs_law.py | 145 | customs_law, _ordinance_data, chapter_expertise |
| test_port_intelligence.py | ~166 | port_intelligence |
| test_email_intent.py | 80 | email_intent |
| test_identity_graph.py | 105 | identity_graph |
| test_tool_calling.py | 61 | tool_definitions, tool_executors, tool_calling_engine |
| test_email_quality_gate.py | 54 | rcb_helpers email quality gate |
| test_verification_engine.py | 46 | verification_engine |
| test_route_eta.py | 65 | route_eta |
| Others | ~456 | Various modules |

### Modules With NO Tests

| Module | Lines | Risk |
|--------|-------|------|
| `classification_agents.py` | 3,618 | **CRITICAL** — most complex module, zero unit tests |
| `elimination_engine.py` | 2,413 | HIGH — 3 live tests exist but no unit tests |
| `tracker.py` | 2,705 | HIGH — only integration tested via live emails |
| `tool_calling_engine.py` | ~1,100 | HIGH — tool loop untested |
| `overnight_brain.py` | ~1,800 | MEDIUM — budget-capped but untested streams |
| `ocean_tracker.py` | 1,606 | LOW — carrier APIs not configured |

### Code Metrics

| Metric | Value |
|--------|-------|
| Total lib/*.py files | ~35 |
| Total lines (lib/) | 64,231 |
| Largest file | `classification_agents.py` (3,618 lines) |
| Feature flags | 4 (all hardcoded True) |
| Firestore collections | 83 registered |
| Active tools | 33 |
| Cloud Functions | 27 |
| Scheduled functions | 14 |

---

## SECTION 9: CI/CD PIPELINE

### Workflows

| Workflow | Trigger | Duration | Status |
|----------|---------|----------|--------|
| RCB Tests | push/PR to main | ~36s | Run #259 GREEN |
| Deploy to Firebase | push to main | ~3m41s | Run #249 GREEN |
| Overnight Learn | scheduled (nightly) | Variable | Not audited |

### CI Findings

| ID | Issue | Severity | Impact |
|----|-------|----------|--------|
| CI-1 | `deploy.yml` uses `continue-on-error: true` | MEDIUM | Deploy failures appear GREEN |
| CI-2 | All 27 functions deployed on every push | LOW | Slow, HTTP 409 conflicts |
| CI-3 | No dependency vulnerability scanning | HIGH | CVEs undetected |
| CI-4 | No secrets scanning in CI | MEDIUM | Accidental key commits possible |
| CI-5 | Tests run sequentially, no parallelization | LOW | 36s is fast enough currently |

### Today's CI Runs (22/02/2026)

| Run | Workflow | Commit | Status | Duration |
|-----|----------|--------|--------|----------|
| #259 | RCB Tests | `84d9d12` (Hebrew justification fix) | GREEN | 36s |
| #258 | RCB Tests | `3257e90` (Session 53 strategic analysis) | GREEN | 43s |
| #249 | Deploy to Firebase | `84d9d12` | GREEN | 3m 41s |
| #248 | Deploy to Firebase | `3257e90` | GREEN | 1m 42s |
| #247 | Deploy to Firebase | `38676de` (Session 50 audit) | GREEN | 1m 39s |

All 5 runs passed. The 3 new commits since last local sync:
1. `40077f3` — tracker send_authorized unlocks CC emails from internal senders
2. `3d81045` — remove redundant external send block
3. `84d9d12` — Section 9 justification renders in Hebrew (decision_he + reasoning_he)

---

## SECTION 10: OVERNIGHT BRAIN & SELF-LEARNING

### Nightly Schedule (Jerusalem Time)

| Time | Function | Streams/Steps | Budget |
|------|----------|---------------|--------|
| 07:00 | `rcb_daily_digest` | Morning port digest | — |
| 14:00 | `rcb_afternoon_digest` | Afternoon port digest | — |
| 20:00 | `rcb_overnight_brain` | 12 streams (A-H) | $3.50 cap |
| 02:00 | `rcb_nightly_learn` | 4-step index builder | — |
| 02:00 | `rcb_overnight_audit` | Diagnostic scan | — |
| 02:00 | `rcb_daily_backup` | 4 collections → GCS | — |
| 03:30 | `rcb_ttl_cleanup` | TTL cleanup (backup-guarded) | — |
| 04:00 | `rcb_download_directives` | Shaarolami scrape | — |

### Brain Efficiency Findings

| ID | Issue | Severity | Impact |
|----|-------|----------|--------|
| OB-1 | Stream 1 re-reads ALL 11,753 tariff docs nightly | MEDIUM | $0.21/month wasted |
| OB-2 | Stream 2 re-reads ALL rcb_processed docs nightly | MEDIUM | Growing cost |
| OB-3 | 3 functions compete at 02:00 (nightly_learn, audit, backup) | MEDIUM | Firestore contention |
| OB-4 | Checkpoint key uses UTC date — can flip mid-run | LOW | Edge case |
| SL-1 | Regression guard only checks today's classifications | MEDIUM | Yesterday's regressions missed |
| SL-2 | `check_classification_memory()` reads 500 docs per call | LOW | Expensive client-side filter |

---

## SECTION 11: STRATEGIC RECOMMENDATIONS (Priority Order)

### Immediate (This Week)

1. **Restore external recipient blocking** (CRIT-1) — Add `@rpa-port.co.il` domain check to `helper_graph_send()` and `helper_graph_reply()` with security_log writes. This is a 15-line fix.

2. **Add TTL to `_gemini_quota_exhausted`** (CRIT-2) — Store `_gemini_quota_exhausted_at` timestamp, auto-reset after 60 seconds. 5-line fix.

3. **Remove `query_tariff()` full-stream** (CRIT-3) — The tool engine's `search_tariff` already does indexed queries. Remove the legacy full-stream call. Saves ~$21/month in Firestore reads.

4. **Fix monitor agent retry logic** (CRIT-4) — Restrict retry to emails with `type == "classification"` in `rcb_processed`, or remove automated deletion entirely.

### Short Term (This Month)

5. **Upgrade Gemini to paid tier** — $3-10/month eliminates all 429-related cost spikes and Claude fallback.

6. **Add `send_authorized` promotion** (HIGH-1) — When a team member sends a direct email about a CC-originated deal, promote to `True`.

7. **Pin dependency versions** (HIGH-7) — Use `pip freeze` to create exact version pins.

8. **Add dependency scanning to CI** (HIGH-8) — `pip audit` in test workflow.

9. **Route `_fetch_seller_website()` through `_safe_get()`** (HIGH-3) — Prevent SSRF.

### Medium Term (Next Sprint)

10. **Reduce system prompt size** — Only include relevant sections instead of all 22. Save ~37.5K tokens per classification.

11. **Test coverage for `classification_agents.py`** — The most complex module (3,618 lines) has zero unit tests.

12. **Wire identity graph search into deal matching** — Currently write-only.

13. **Add real-time cost tracking to Firestore** — Replace the per-invocation `_CostTracker` with persistent daily/monthly aggregation.

14. **Evaluate Gemini Pro for Agent 2** — Could save $60-$150/month vs Claude Sonnet 4.

---

## APPENDIX A: COMPLETE FINDING INDEX

| ID | Severity | Category | One-Line Summary |
|----|----------|----------|-----------------|
| CRIT-1 | CRITICAL | Security | External recipient blocking documented but absent from code |
| CRIT-2 | CRITICAL | Cost | Gemini quota flag sticks across Cloud Function invocations |
| CRIT-3 | CRITICAL | Efficiency | query_tariff() streams 11,753 docs per classification |
| CRIT-4 | CRITICAL | Pipeline | Monitor agent creates email re-processing storms |
| HIGH-1 | HIGH | Pipeline | send_authorized never promoted for CC-originated deals |
| HIGH-2 | HIGH | Pipeline | Classify+clarification double-fires on missing attachment |
| HIGH-3 | HIGH | Security | Seller website tool bypasses domain allowlist (SSRF) |
| HIGH-4 | HIGH | Processing | Verification engine module-level cache never refreshes |
| HIGH-5 | HIGH | Processing | Cross-reference confidence adjustments may not apply |
| HIGH-6 | HIGH | Security | 7 bare except: clauses remain |
| HIGH-7 | HIGH | Infra | No pinned upper-bound versions in requirements.txt |
| HIGH-8 | HIGH | Infra | No dependency vulnerability scanning in CI |
| M-P1 | MEDIUM | Pipeline | datetime.utcnow() deprecated |
| M-P2 | MEDIUM | Pipeline | Rate limit case mismatch |
| M-P3 | MEDIUM | Pipeline | Gap 2 auto-trigger is dead |
| M-P4 | MEDIUM | Pipeline | Full collection scans every 5 min |
| M-P5 | MEDIUM | Extraction | Scanned PDF only renders page 1 |
| M-P6 | MEDIUM | Intent | CUSTOMS_QUESTION regex false-positives |
| M-P7 | MEDIUM | Pipeline | TOCTOU race in classification readiness |
| M-P8 | MEDIUM | Pipeline | follower_email may be external |
| M-P9 | MEDIUM | Pipeline | Identity graph search not used |
| M-P10 | MEDIUM | Efficiency | Identity graph 144 reads per link |
| M-CL1 | MEDIUM | Processing | Feature flags hardcoded True |
| M-CL2 | MEDIUM | Processing | JSON parsing via string slicing |
| M-CL3 | MEDIUM | Processing | Forced final answer unverified |
| M-CL4 | MEDIUM | Cost | System prompt 23.5K chars per round |
| M-CL5 | MEDIUM | Processing | GIR 3b essential character order-dependent |
| M-CL6 | MEDIUM | Processing | Section scope fails on colloquial terms |
| M-CL7 | MEDIUM | Processing | Verification confidence asymmetric |
| M-CL8 | MEDIUM | Cost | Legal context includes all 22 sections always |
| M-CL9 | MEDIUM | Efficiency | Pre-enrichment trigger keywords overlap |
| M-CL10 | MEDIUM | Processing | search_open_beauty required=[] |
| M-CL11 | MEDIUM | Cost | audit_before_send retry identical prompt |
| M-O2 | MEDIUM | Output | Quality gate HS regex fragile |
| M-O3 | MEDIUM | Docs | CLAUDE.md claims features absent from code |
| OB-1 | MEDIUM | Overnight | Stream 1 re-reads 11,753 tariff docs nightly |
| OB-2 | MEDIUM | Overnight | Stream 2 re-reads all rcb_processed nightly |
| OB-3 | MEDIUM | Overnight | 3 functions compete at 02:00 |
| SL-1 | MEDIUM | Learning | Regression guard only checks today |
| CI-1 | MEDIUM | CI/CD | Deploy failures silently pass |
| CI-4 | MEDIUM | CI/CD | No secrets scanning |
| ... | LOW | Various | 18 additional LOW findings (see sections above) |

---

## APPENDIX B: GITHUB ACTIONS STATUS (22/02/2026)

### Deploy to Firebase
- **#249** GREEN — `84d9d12` (Hebrew justification fix) — 3m 41s
- **#248** GREEN — `3257e90` (Session 53 strategic analysis) — 1m 42s
- **#247** GREEN — `38676de` (Session 50 comprehensive audit) — 1m 39s

### RCB Tests
- **#259** GREEN — `84d9d12` — 36s
- **#258** GREEN — `3257e90` — 43s

All CI green. No deploy failures in recent history.

---

*Audit generated 22/02/2026 14:57 Israel Time*
*Auditor: Claude Opus 4.6 — 6 parallel agents, ~500K tokens analyzed*
*Next action: Give this audit to Claude AI for implementation priorities*
